{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://shwetkm.github.io/upxlogo.png\"></img>\n",
    "\n",
    "# Python Advanced - Data Science Foundation\n",
    "\n",
    "**SET THE WORKING DIRECTORY SO THAT WE DO NOT HAVE TO THINK ABOUT PATH PROBLEMS**\n",
    "\n",
    "Please ensure all your folder names <font color='red'><b>do not have a space & use forward slash (/)</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "your_local_path=\"F:/UpX-Series/DataScience/DS_Batches/Company/SFO_Kerala/Session6/PythonAdvanced/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction to NumPy**\n",
    "\n",
    "NumPy (short form for Numerical Python) is the most fundamental package designed for scientific computing and data analysis. Most of the other packages such as pandas, statsmodels are built on top of it, and is an important package to know and learn about. At the heart of NumPy is a data structure called **ndarray**. ndarray is a basically a multi-dimensional array that is built specifically for the purpose of numerical data analysis. Python also has array capabilities, but they are more generic. <b>The advantage of using ndarray is that processing is extremely efficient and fast.</b> \n",
    "\n",
    "You can perform standard mathematical operations on either individual elements or complete array. The range of functions covered is <b>linear algebra, statistical operations, and other specialized mathematical operations</b>. For our purpose, we need to know about <b>ndarray and the range of mathematical functions that are relevant to our research purpose</b>. If you already know languages such as C, Fortran, then you can integrate NumPy code with code written in these languages and can pass NumPy arrays seamlessly. \n",
    "\n",
    "From an overall perspective, understanding of <b>NumPy will help us in using pandas effectively as it is built on top of NumPy and frequently we will also be using functions of NumPy in research work</b>. In the current session, we will only look at some of the most important features of NumPy. For a full listing of NumPy features, please visit http://wiki.scipy.org/Numpy_Example_List .\n",
    "\n",
    "Possible application of NumPy package in research work are:\n",
    "<i>\n",
    "+ Algorithmic operations such as sorting, grouping and set operations\n",
    "+ Performing repetitive operations on whole arrays of data without using loops\n",
    "+ Data merging and alignment operations\n",
    "+ Data indexing, filtering, and transformation on individual elements or whole arrays\n",
    "+ Data summarization and descriptive statistics\n",
    "</i>\n",
    "**Installing NumPy**\n",
    "\n",
    "In order to check if NumPy is installed, go to Package Manager and type NumPy. You will get a list of packages with names closely matching to NumPy. For our purpose, we need to focus on package named numpy 1.xx. If the package is not installed, click on Install. \n",
    "\n",
    "**Importing NumPy**\n",
    "\n",
    "In order to be able to use NumPy, first import it using import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above statement will import all of NumPy into your workspace. For starters its good, but if you are doing performance intensive work, then saving space is of importance. In such cases, you can import specific modules of NumPy by using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarray\n",
    "The most important data structure in NumPy is an n-dimensional array object. Using ndarray, you can store large multidimensional datasets in Python. Being an array, you can <b>perform mathematical operations on these arrays either one element at a time or on complete arrays without using loops</b>. The way to initialize an array object is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# why we need numpy\n",
    "\n",
    "distance = [45,50,35]\n",
    "speed = [5,10,7]\n",
    "time = distance/speed    # In regular array we cannot do element wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How we have overcome the prior challenge using \n",
    "dist = np.array(distance)\n",
    "spd = np.array(speed)\n",
    "time= dist/spd\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = array(np.arange(10))                           #arange function here works as a sequence or counter in increments of 1\n",
    "print ('array:                ', anarray)\n",
    "print()\n",
    "print()\n",
    "\n",
    "anarray = array(np.arange(5,56,5))                 #arange function here works as a sequence or counter in increments of 5\n",
    "print ('anarray:              ', anarray)\n",
    "print()\n",
    "print()\n",
    "\n",
    "onemorearray = array(np.linspace(1,5,4))           #linspace sequence of evenly spaced numbers\n",
    "print ('onemorearray:         ', onemorearray)\n",
    "print ('Rounded onemorearray: ', np.round(onemorearray,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each ndarray are associated two attributes: shape of the array, and type of the array. The <font color='red'><b>shape</b> of the array tells you about <b><u>dimensionality</u></b> of the array (rows and columns), and <b>type</b> of the array tells you about the <b><u>data type</u></b> contained</font> in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('********* Data Array *********')\n",
    "data = np.array((32,45,123,756,23,2123))    # Think of this as items in an array structure row-wise\n",
    "print (data)\n",
    "print('Shape: ',data.shape)\n",
    "print('Type: ',data.dtype)\n",
    "print('Size: ',data.size)\n",
    "print('Dimension: ',data.ndim)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('********* Data2 Array *********')\n",
    "data2 = np.array([(1,2,3,4),(5,6,7,8)])    # Think of this as items in a 2D array structure row & column wise\n",
    "print (data2)\n",
    "print('Shape: ',data2.shape)\n",
    "print('Type: ',data2.dtype)\n",
    "print('Size: ',data2.size)\n",
    "print('Dimension: ',data2.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let us understand the reshape function\n",
    "\n",
    "import numpy as np\n",
    "a = np.arange(16).reshape(4,4)\n",
    "print(a.shape)\n",
    "print (a)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "b=a.reshape(2,8)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros(10).reshape(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros((3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ones(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.ones((5,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.eye(3) # creates a 5*5 identity matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.diag(array([2,2,2,2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.array([5,10,15,20,25],dtype=np.float)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.ndim, b.shape, b.size          # Know your data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.random((5,9))         # Generate random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.linspace(0,15,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add = arr+1\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sin_arr = np.sin(arr)\n",
    "sin_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(arr,sin_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Indexing the nparrary ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array = np.random.random((2,3))\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array.reshape(1,6)        #array still Retains the original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array[1,2]                #array still Retains the original shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "print(st.norm(70,2).pdf(72))                   #*****************************\n",
    "\n",
    "# Demo of stats functions\n",
    "from scipy.stats import norm\n",
    "\n",
    "# pick a random sample of 10 points from standard normal distribution\n",
    "norm.rvs(loc=0,scale=1,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Selecting on certain criteria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_score = np.array([[65,55,45,63],[28,92,88,65]] )\n",
    "passing_score = test_score > 50\n",
    "print(passing_score)\n",
    "test_score[passing_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=2\n",
    "X=2\n",
    "x_123 =2\n",
    "123_x = 2                  #invalid token\n",
    "_x =2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas**\n",
    "\n",
    "Pandas is the primary package for performing data analysis tasks in Python. pandas derives its name from <b>PANel Data AnalysiS</b> and is the fundamental package that provides <b>relational data structures (think Excel, SQL type) and a host of capabilities to play with those data structures</b>. It is the most widely used package in Python for data analysis tasks, and is very good to work with <b>cross sectional, time series, and panel data analysis</b>. Python sits on top of NumPy and can be used with NumPy arrays and the functions in NumPy. How is pandas suited for a researcher’s needs:\n",
    "<i>\n",
    "+ Has a tabular data structure that can hold both <b>homogenous and heterogenous data</b>.\n",
    "+ Very <b>good indexing capabilities</b> that makes data alignment and merging easy.\n",
    "+ Good <b>time series functionality</b>. No need to use different data structures for time series and cross sectional data. Allows for both <b>ordered and unordered time-series data</b>.\n",
    "+ A host of <b>statistical functions</b> developed around NumPy and pandas that makes a researcher’s task easy and fast.\n",
    "+ Programming is lot <b>simpler and faster</b>.\n",
    "+ Easily handles <b>data manipulation and cleaning</b>.\n",
    "+ Easy to expand and shorten data sets. <b>Comprehensive merging, joins, and group by functionality to join multiple data sets</b>.\n",
    "</i>\n",
    "\n",
    "**Installing pandas** \n",
    "\n",
    "In order to check if pandas is installed, go to Package Manager and type pandas. By default, pandas already comes installed with a distribution of Canopy. If the package is not installed, click on Install.\n",
    "\n",
    "**Importing pandas**\n",
    "\n",
    "In order to be able to use NumPy, first import it using import statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd #this will import pandas into your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  #we will be using numpy functions so import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Structures in pandas**\n",
    "\n",
    "There are two basic data structures in pandas: <b><i>Series and DataFrame</i></b>\n",
    "\n",
    "**Series:** It is similar to a NumPy 1-dimensional array. In addition to the values that are specified by the programmer, <b><i>pandas attaches a label to each of the values</i></b>. If the labels are not provided by the programmer, then pandas assigns labels ( 0 for first element, 1 for second element and so on). A benefit of assigning labels to data values is that it becomes easier to perform manipulations on the dataset as the whole dataset becomes more of a dictionary where each value is associated with a label. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series1 = pd.Series([10,20,30,40])\n",
    "series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to specify custom index values rather than the default ones provided, you can do so using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series2 = pd.Series([10,20,30,40,50], index=['one','two','three','four','five'])\n",
    "print(series2)\n",
    "series2.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ways of accesing elements in a Series object are similar to what we have seen in NumPy, and you can perform NumPy operations on Series data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series2[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series2['five']                      # Fetch single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series2[['one', 'three', 'five']]    # Fetch multiple data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series2[[0,1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series2 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series2 ** 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series2[series2>30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sqrt(series2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a dictionary, you can create a Series data structure from that dictionary. Suppose you are interested in EPS values for firms and the values come from different sources and is not clean. In that case you dont have to worry about cleaning and aligning those values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = [90, 91, 92, 93, 94, 95]\n",
    "f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}\n",
    "firm1 = pd.Series(f1,index=years)\n",
    "firm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2 = {90:14,92:9, 93:13, 94:5}\n",
    "firm2 = pd.Series(f2,index=years)\n",
    "firm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = [90, 91, 92, 93, 94, 95,96,97,98,99]\n",
    "f3 = {93:10, 94:12, 95: 13}\n",
    "firm3 = pd.Series(f3, index=years)\n",
    "firm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NaN stands for missing or NA</b> values in pandas. Make use of isnull() function to find out if there are any missing values in the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.isnull(firm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key feature of Series data is structures is that you <b>don't have to worry about data alignment</b>. For example, if we have run a word count program on two different files and we have the following data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict1 = {'finance': 10, 'earning': 5, 'debt':8}\n",
    "dict2 = {'finance' : 8, 'compensation':4, 'earning': 9}\n",
    "count1 = pd.Series(dict1)\n",
    "count2 = pd.Series(dict2)\n",
    "print (count1)\n",
    "print ()\n",
    "print ()\n",
    "print (count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to calculate the sum of common words in combined files, then we dont have to worry about data alignment. If we want to include all words, then we can take care of NaN values and compute the sum. By default, Series data structure ignores NaN values. NaN values stand for missing data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (type(count1))\n",
    "count1+count2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Frame**\n",
    "\n",
    "DataFrame is a tabular data structure in which data is laid out in rows and column format (similar to a CSV and SQL file), but it can also be used for higher dimensional data sets. The DataFrame object can contain homogenous and heterogenous values, and can be thought of as a logical extension of Series data structures. In contrast to Series, where there is one index, a DataFrame object has one index for column and one index for rows. This allows flexibility in accessing and manipulating data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({'price':[95, 25, 85, 41, 78],\n",
    "                     'ticker':['AXP', 'CSCO', 'DIS', 'MSFT', 'WMT'],\n",
    "                     'company':['American Express', 'Cisco', 'Walt Disney','Microsoft', 'Walmart']})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a column is passed with no values, it will simply have NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[4,1]          # cannot do label indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[[4],['company']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[:,['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.loc[[0],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access a column, simply mention the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.ix[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[data.price > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to add additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['Year'] = 2014\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['pricesquared'] = data.price**2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data['pricesquared']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['pricesquared'] = np.NaN\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['sequence'] = np.arange(1,6)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = data\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add new row\n",
    "\n",
    "#data1 = data1.reset_index(drop=True)\n",
    "#data1.loc[len(data1)] = ['Wipro',5,'WIPRO',6]\n",
    "#data1 = data1.drop(2)\n",
    "\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newdata = data.drop(2)\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = [90, 91, 92, 93, 94, 95]\n",
    "f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}\n",
    "firm1 = pd.Series(f1,index=years)\n",
    "firm1\n",
    "f2 = {90:14,92:9, 93:13, 94:5}\n",
    "firm2 = pd.Series(f2,index=years)\n",
    "firm2\n",
    "f3 = {93:10, 94:12, 95: 13}\n",
    "firm3 = pd.Series(f3,index=years)\n",
    "firm3\n",
    "df1 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years)\n",
    "df1\n",
    "df1.Firm1 = firm1\n",
    "df1.Firm2 = firm2\n",
    "df1.Firm3 = firm3\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dft = df1.T\n",
    "dft\n",
    "del dft[90]\n",
    "dft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass a number of data structures to DataFrame such as a ndarray, lists, dict, Series, and another DataFrame. You can also reindex to confirm to data to a new index. Reindexing is a powerful feature that allows you to access data in a number of different ways, and also to confirm data to some new time series or other index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reindexdf1 = df1.reindex([88,89,90,91,92,93,94,95,96,97,98])\n",
    "reindexdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reindexdf1 = df1.reindex(np.arange(1988,2008))\n",
    "reindexdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years1 = [90, 91, 92, 93, 94, 95]\n",
    "f4 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}\n",
    "firm4 = pd.Series(f4,index=years)\n",
    "f5 = {90:14,91:12, 92:9, 93:13, 94:5, 95:8}\n",
    "firm5 = pd.Series(f5,index=years)\n",
    "f6 = {90:8, 91: 9, 92:9,93:10, 94:12, 95: 13}\n",
    "firm6 = pd.Series(f6,index=years)\n",
    "df2 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years1)\n",
    "df2.Firm1 = firm4\n",
    "df2.Firm2 = firm5\n",
    "df2.Firm3 = firm6\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reindexdf2 = df2.reindex([88,89,90,91,92,93,94,95,96,97,98], fill_value=0)\n",
    "reindexdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to make it more readable and list 21 years data.\n",
    "df3=df2\n",
    "df3=df3.set_index(np.arange(1990,1996))\n",
    "df3=df3.reindex(np.arange(1988,2009))\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you have forward & backfill (bfill) method to fill values forward & backwards respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reindexdf3 = df2.reindex([88,89,90,91,92,93,94,95,96,97,98], method='ffill')\n",
    "reindexdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reindexdf4 = df2.reindex([88,89,90,91,92,93,94,95,96,97,98], method='bfill')\n",
    "reindexdf4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use NumPy functions inside DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate random sample from a standard normal distribution\n",
    "np.random.seed(2) # what is this doing?\n",
    "dataframe = pd.DataFrame(np.random.randn(3,3),columns=['one','two','three'])\n",
    "dataframe\n",
    "\n",
    "# Try tab for the other distributions\n",
    "#np.random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.abs(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = lambda x:x.max()-x.min() # by default it will apply the function by columnns\n",
    "dataframe.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.apply(f,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = lambda x: x - np.mean(x)\n",
    "dataframe.apply(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return pd.Series([np.mean(x), x.max(), x.min()], index=['mean','max','min'])\n",
    "dataframe.apply(f, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "dataframe = pd.DataFrame(np.random.randn(3,3),columns=['one','two','three'])\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.sort_index(by='two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.sort_values(by=['one','two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (dataframe)\n",
    "dataframe.cumsum(axis=0) # what do you think is happening here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have non-numeric data, then applying describe function would produce statistics such as <b>count, unique, frequency</b>. In addition to this, you can also calculate <b>skewness (skew), kurtosis (kurt), percent changes, difference, and other statistics</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the example of percent change calculation where we pull company stock price data from Yahoo Finance website and apply percent change method on it. <b>Pandas</b> provides a number of <b>web interfaces</b> such as <i>Yahoo Finance, Google Finance, St. Louis FED, Ken French data library, World Bank</i>. Here, we look at example of Yahoo Finance. Later, we will look at other options. To extract data from these websites, you need to use <b>pandas.io.data</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conda install -c anaconda pandas-datareader=0.4.0\n",
    "import pandas_datareader as pdr\n",
    "from pandas_datareader import data, wb\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "start = datetime.datetime(2017, 5, 1)\n",
    "end = datetime.datetime(2017, 5, 31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl = web.DataReader('AAPL','google', start, end)\n",
    "aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute 10 days moving average\n",
    "mov_avg = pd.rolling_mean(aapl.Volume,5)\n",
    "mov_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute lead and lag\n",
    "aapl\n",
    "aapl['lag1'] = aapl.Close.shift(1)\n",
    "aapl['lead1'] = aapl.Close.shift(-1)\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl.pct_change()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mov_avg.plot(label='Mov Avg')\n",
    "aapl.Volume.plot(label='Volume')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to pull data from a number of companies, you can do so by specifying a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata = []\n",
    "for company in ['GOOG','AAPL','CSCO','DIS','MSFT']:\n",
    "    data=web.DataReader(company,'google', start, end)\n",
    "    data['Firm'] = company\n",
    "    alldata.append(data)\n",
    "    \n",
    "data =pd.concat(alldata)\n",
    "print (type(alldata))\n",
    "print (type(data))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cars = pd.read_csv(your_local_path+'cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(cars)\n",
    "cars.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run Correlation to find the most correlated variable to MPG\n",
    "round(cars.corr(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run covariance\n",
    "cars.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "carsgrp = cars.groupby('Cylinders').mean()     # Data GROUP BY\n",
    "carsgrp\n",
    "round(carsgrp,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pivot table demo\n",
    "table = pd.pivot_table(cars, values='Actual_MPG', index=['Origin', 'Cylinders'],columns=['Year'], aggfunc=np.median)\n",
    "round(table,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scatter plots\n",
    "# first let's create a x variable\n",
    "plt.scatter(cars.Weight,cars.Actual_MPG,color ='purple')\n",
    "plt.xlabel ('Weight')\n",
    "plt.ylabel ('Actual_MPG')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scatter plots\n",
    "# first let's create a x variable\n",
    "plt.plot(carsgrp.Horsepower,carsgrp.Actual_MPG,'b',linestyle = '--',color ='blue', linewidth = 4.5)\n",
    "plt.xlabel ('Horsepower')\n",
    "plt.ylabel ('Actual_MPG')\n",
    "plt.title ('Horsepower vs MPG Trend')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#left # the left side of the subplots of the figure\n",
    "#right # the right side of the subplots of the figure\n",
    "#bottom # the bottom of the subplots of the figure\n",
    "#top # the top of the subplots of the figure\n",
    "#wspace # the amount of width reserved for blank space between subplots\n",
    "#hspace # the amount of height reserved for white space between subplots'''\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(hspace= 0.2, wspace= 0.2)\n",
    "plt.subplot(2,2,1)\n",
    "plt.title ('Actual_MPG')\n",
    "plt.plot(cars.Actual_MPG,'r')\n",
    "plt.subplot(2,2,2)\n",
    "plt.title ('Weight')\n",
    "plt.plot(cars.Weight, 'b')\n",
    "plt.subplot(2,2,3)\n",
    "plt.title ('Cylinders')\n",
    "plt.plot(cars.Cylinders, 'g')\n",
    "plt.subplot(2,2,4)\n",
    "plt.title ('Horsepower')\n",
    "plt.plot(cars.Horsepower,'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplots_adjust(hspace= 0.2, wspace= 0.1)\n",
    "plt.subplot(1,4,1)\n",
    "plt.title ('Actual_MPG')\n",
    "plt.plot(cars.Actual_MPG,'r')\n",
    "plt.subplot(1,4,2)\n",
    "plt.title ('Weight')\n",
    "plt.plot(cars.Weight, 'b')\n",
    "plt.subplot(1,4,3)\n",
    "plt.title ('Cylinders')\n",
    "plt.plot(cars.Cylinders, 'g')\n",
    "plt.subplot(1,4,4)\n",
    "plt.title ('Horsepower')\n",
    "plt.plot(cars.Horsepower,'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "# color pallete- http://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "print (iris.head())\n",
    "sns.pairplot(iris, hue=\"species\", palette=\"husl\", size =5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example of boxplots\n",
    "# http://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "sns.boxplot(data=iris, orient=\"v\", palette=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='Origin',y='Actual_MPG',data=cars,linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Heatmap- first load library and datasets\n",
    "flight_data = sns.load_dataset(\"flights\")\n",
    "flight_data.head()\n",
    "flight_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rearrange data\n",
    "flight_data = flight_data.pivot('month','year','passengers')\n",
    "flight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate map\n",
    "sns.heatmap(flight_data, annot= True, fmt = \"d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(flight_data, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\n",
    "sizes = [15, 30, 45, 10]\n",
    "explode = (0.1, 0.2, 0.1, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "plt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Data**\n",
    "\n",
    "pandas have a number of features to deal with missing data. We have seen an example of the case of descriptive statistics, where missing values are not taken into account while calculating the descriptive statistics. Missing data is denoted by NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = [90, 91, 92, 93, 94, 95]\n",
    "f1 = {90:8, 91:9, 92:7, 93:8, 94:9, 95:11}\n",
    "firm1 = pd.Series(f1,index=years)\n",
    "firm1\n",
    "f2 = {90:14,92:9, 93:13, 94:5}\n",
    "firm2 = pd.Series(f2,index=years)\n",
    "firm2\n",
    "f3 = {93:10, 94:12, 95: 13}\n",
    "firm3 = pd.Series(f3,index=years)\n",
    "firm3\n",
    "df3 = pd.DataFrame(columns=['Firm1','Firm2','Firm3'],index=years)\n",
    "df3\n",
    "df3.Firm1 = firm1\n",
    "df3.Firm2 = firm2\n",
    "df3.Firm3 = firm3\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3['Firm2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nadeleted = firm2.dropna()\n",
    "nadeleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of DataFrame, <b>if you use dropna, it deletes entire row by default</b>. Another way is to drop only <b>those rows that are all NA</b>. If you want to <b>drop columns, pass axis=1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleandf3 = df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleandf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean2 = df3.dropna(how = 'any')\n",
    "clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean2 = df3.dropna(how = 'all')\n",
    "clean2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columndrop = df3.dropna(axis=1)\n",
    "columndrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholddf = df3.dropna(thresh=2)\n",
    "thresholddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fillna1 = df3.fillna(0)\n",
    "fillna1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df3)\n",
    "fillna2 = df3.fillna({'Firm1':8, 'Firm2': 10, 'Firm3':14})\n",
    "fillna2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fillna3 = df3.fillna(method='ffill')\n",
    "fillna3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fillna4 = df3.fillna(method='bfill',limit=2)\n",
    "fillna4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (df3)\n",
    "fillna5 = df3.fillna(df3.mean())\n",
    "fillna5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical Indexing**\n",
    "\n",
    "Hierarchical indexing allows you to have <b>index on an index (multiple index)</b>. It is an important feature of pandas using which you can <b>select subsets of data and perform independent analyses</b> on them. For example, suppose you have <b>firm prices data and the data is indexed by firm name</b>. On top of that, you can <b>index firms by industry</b>. Thus, industry becomes an index on top of firms. You can then perform analyses either on individual firm, or on group of firms in an industry, or on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "h_i_data = pd.Series(np.random.randn(10),index=[['Ind1','Ind1','Ind1','Ind1','Ind2','Ind2','Ind2','Ind3','Ind3','Ind3'],\n",
    "                                              [1,2,3,4,1,2,3,1,2,3]])\n",
    "h_i_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data['Ind3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data['Ind1':'Ind3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data[['Ind1','Ind3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data.unstack(level=0) # pivot an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data.unstack().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data.unstack(level=1) # pivot an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data.sum(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data.sum(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_i_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IO in pandas**\n",
    "\n",
    "In this section, we will focus on I/O from text files, csv, excel, and sql files as well as getting data from web such as Yahoo! Finance. Using functions in pandas, you can read data as a DataFrame object. \n",
    "\n",
    "**Reading a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roedatacsv = pd.read_csv(your_local_path+'roedata.csv')\n",
    "#roedatacsv\n",
    "roedatacsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file does not have a header, then you can either let pandas assign default headers or you can specify custom headers. If you want industry name to be the index of DataFrame, you can achieve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roedatacsv = pd.read_csv(your_local_path+'roedata.csv', index_col = 'Industry Name' )\n",
    "roedatacsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roedatacsv = pd.read_csv(your_local_path+'roedata.csv', usecols = ['Industry Name','ROE'] )\n",
    "roedatacsv # usecols is used to selectively get the columns that we require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import only selected rows\n",
    "roedatacsv = pd.read_csv(your_local_path+'roedata.csv',nrows=50)\n",
    "roedatacsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capm_dem_data = pd.read_table(your_local_path+'capm_dem.dat',nrows = 50, delimiter=' ',header = None)\n",
    "capm_dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capm_dem_data = pd.read_table(your_local_path+'capm_dem.txt', delimiter=' ',header = None)\n",
    "capm_dem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cars = pd.read_csv(your_local_path+'cars.csv', index_col =['Origin','Cylinders'])\n",
    "cars = cars.sort_index(level=0)\n",
    "cars.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crsp_data = pd.read_table(your_local_path+'crsp.output', sep='\\s+',header = None)\n",
    "crsp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Handling missing values**\n",
    "\n",
    "Some types of missing values are automatically identified by pandas as NaN while importing the data. Those types are NA, NULL, -1.#IND. Additionally, you can also specify a list of missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roemissing = pd.read_csv(your_local_path+'roemissing.csv', na_values=['NULL',-999, 'RP'] )\n",
    "roemissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roemissing = pd.read_csv(your_local_path+'roemissing.csv', na_values={'Number of firms':['NULL',-999],'ROE':['10000.00%']} )\n",
    "roemissing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roedata = pd.read_csv(your_local_path+'roedata.csv')\n",
    "roedata.to_csv(your_local_path+'roedatawrite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roedata = pd.read_csv(your_local_path+'roedata.csv')\n",
    "roedata.to_csv(your_local_path+'roedatawrite2.csv', index=False, columns=['Industry Name','ROE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_frame = pd.DataFrame({'key': range(5), \n",
    "                           'left_value': ['a', 'b', 'c', 'd', 'e']})\n",
    "right_frame = pd.DataFrame({'key': range(2, 7), \n",
    "                           'right_value': ['f', 'g', 'h', 'i', 'j']})\n",
    "print(left_frame)\n",
    "print()\n",
    "print(right_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(left_frame, right_frame, on='key', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(left_frame, right_frame, on='key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(left_frame, right_frame, on='key', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(left_frame, right_frame, on='key', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([left_frame, right_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([left_frame, right_frame], axis=1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
